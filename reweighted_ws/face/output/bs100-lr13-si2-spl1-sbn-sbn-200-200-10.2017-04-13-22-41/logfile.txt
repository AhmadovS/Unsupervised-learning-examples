[22:41:59] trainer         compiling do_step
[22:42:02] trainer         compiling do_sleep_step
[22:42:04] trainer         Dataset contains 3374 datapoints in 33 mini-batches (100 datapoints per mini-batch)
[22:42:04] trainer         Using 1 training samples
[22:42:04] trainer         lr_p=1.0e-03, lr_q=1.0e-03, lr_s=1.0e-03, lr_decay=1.0e+00 layer_discount=1.00
[22:42:04] model           Saving model parameters
[22:42:04] valiset         compiling do_loglikelihood
[22:42:05] valiset         (419 datpoints, 1 samples): LL=-240.70 +-5.66; Hp=[-240.69 -111.3  -111.31   -5.61]
[22:42:05] trainer         Starting epoch 0...
[22:42:07] trainer         Completed epoch 1 in 1.4s (41.1ms/step). Calling epoch_monitors...
[22:42:07] model           Saving model parameters
[22:42:07] valiset         (419 datpoints, 1 samples): LL=-35.58 +-10.81; Hp=[ -35.03 -111.26 -111.66   -5.5 ]
[22:42:07] termination     Validation LL=-35.58 (increased by  nan %)
[22:42:07] trainer         Starting epoch 1...
[22:42:08] trainer         Completed epoch 2 in 1.4s (42.1ms/step). Calling epoch_monitors...
[22:42:08] model           Saving model parameters
[22:42:08] valiset         (419 datpoints, 1 samples): LL=-33.32 +-12.33; Hp=[ -32.64 -110.39 -111.12   -5.57]
[22:42:08] termination     Validation LL=-33.32 (increased by 6.34 %)
[22:42:08] trainer         Starting epoch 2...
[22:42:10] trainer         Completed epoch 3 in 1.4s (41.7ms/step). Calling epoch_monitors...
[22:42:10] model           Saving model parameters
[22:42:10] valiset         (419 datpoints, 1 samples): LL=-32.78 +-12.22; Hp=[ -31.99 -111.53 -111.17   -5.66]
[22:42:10] termination     Validation LL=-32.78 (increased by 1.64 %)
[22:42:10] trainer         Starting epoch 3...
[22:42:11] trainer         Completed epoch 4 in 1.4s (42.7ms/step). Calling epoch_monitors...
[22:42:11] model           Saving model parameters
[22:42:12] valiset         (419 datpoints, 1 samples): LL=-30.27 +-10.46; Hp=[ -29.34 -110.88 -110.75   -5.78]
[22:42:12] termination     Validation LL=-30.27 (increased by 7.64 %)
[22:42:12] trainer         Starting epoch 4...
[22:42:13] trainer         Completed epoch 5 in 1.4s (41.8ms/step). Calling epoch_monitors...
[22:42:13] model           Saving model parameters
[22:42:13] valiset         (419 datpoints, 1 samples): LL=-29.44 +-9.92; Hp=[ -28.57 -110.89 -110.65   -5.59]
[22:42:13] termination     Validation LL=-29.44 (increased by 2.75 %)
[22:42:13] trainer         Starting epoch 5...
[22:42:14] trainer         Completed epoch 6 in 1.4s (42.7ms/step). Calling epoch_monitors...
[22:42:14] model           Saving model parameters
[22:42:15] valiset         (419 datpoints, 1 samples): LL=-27.71 +-8.87; Hp=[ -26.64 -109.97 -111.19   -5.68]
[22:42:15] termination     Validation LL=-27.71 (increased by 5.86 %)
[22:42:15] trainer         Starting epoch 6...
[22:42:16] trainer         Completed epoch 7 in 1.4s (41.8ms/step). Calling epoch_monitors...
[22:42:16] model           Saving model parameters
[22:42:16] valiset         (419 datpoints, 1 samples): LL=-25.72 +-7.77; Hp=[ -24.38 -110.04 -111.48   -5.68]
[22:42:16] termination     Validation LL=-25.72 (increased by 7.19 %)
[22:42:16] trainer         Starting epoch 7...
[22:42:18] trainer         Completed epoch 8 in 1.4s (42.8ms/step). Calling epoch_monitors...
[22:42:18] model           Saving model parameters
[22:42:18] valiset         (419 datpoints, 1 samples): LL=-24.07 +-7.18; Hp=[ -22.71 -110.47 -110.68   -5.6 ]
[22:42:18] termination     Validation LL=-24.07 (increased by 6.41 %)
[22:42:18] trainer         Starting epoch 8...
[22:42:19] trainer         Completed epoch 9 in 1.4s (42.0ms/step). Calling epoch_monitors...
[22:42:19] model           Saving model parameters
[22:42:19] valiset         (419 datpoints, 1 samples): LL=-22.47 +-6.52; Hp=[ -21.09 -111.01 -110.69   -5.58]
[22:42:19] termination     Validation LL=-22.47 (increased by 6.66 %)
[22:42:19] trainer         Starting epoch 9...
[22:42:21] trainer         Completed epoch 10 in 1.4s (42.9ms/step). Calling epoch_monitors...
[22:42:21] model           Saving model parameters
[22:42:21] valiset         (419 datpoints, 1 samples): LL=-20.60 +-5.80; Hp=[ -19.08 -110.63 -109.93   -5.54]
[22:42:21] termination     Validation LL=-20.60 (increased by 8.31 %)
[22:42:21] trainer         Calling final_monitors...
[22:42:21] SampleFromP     compiling do_sample
[22:42:21] SampleFromP     SampleFromP(n_samples=100)
[22:42:21] final-testset   compiling do_loglikelihood
[22:42:23] final-testset   (385 datpoints, 10 samples): LL=-2.69 +-0.30; Hp=[ -1.91 -87.44 -84.85  -4.17]
[22:42:23] final-trainset  compiling do_loglikelihood
[22:42:31] final-trainset  (3374 datpoints, 10 samples): LL=-14.25 +-2.02; Hp=[ -12.28 -109.34 -106.77   -5.23]
[22:42:31] root            Finished. Wrinting metadata
[22:42:31] experiment      Parameter file:   None
[22:42:31] experiment      Output directory: output/bs100-lr13-si2-spl1-sbn-sbn-200-200-10.2017-04-13-22-41/
[22:42:31] experiment      -- Trainer hyperparameter --
[22:42:31] experiment             learning_rate_q: 0.001
[22:42:31] experiment             learning_rate_p: 0.001
[22:42:31] experiment             learning_rate_s: 0.001
[22:42:31] experiment              layer_discount: 1.0
[22:42:31] experiment            monitor_nth_step: 1
[22:42:31] experiment                   n_samples: 1
[22:42:31] experiment                  batch_size: 100
[22:42:31] experiment                        beta: 0.95
[22:42:31] experiment            sleep_interleave: 2
[22:42:31] experiment                weight_decay: 0.0
[22:42:31] experiment                    lr_decay: 1.0
[22:42:31] experiment      -- Model hyperparameter --
[22:42:31] experiment                layer sizes: 784-200-200-10
[22:42:31] experiment                   p-layers: <class 'learning.models.sbn.SBN'> - <class 'learning.models.sbn.SBN'> - <class 'learning.models.sbn.SBN'> - <class 'learning.models.sbn.SBNTop'>
[22:42:31] experiment                   q-layers: <class 'learning.models.sbn.SBN'> - <class 'learning.models.sbn.SBN'> - <class 'learning.models.sbn.SBN'>
